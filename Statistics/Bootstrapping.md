
Bootstrapping refers to random sampling **with replacement**, meaning that once chosen, an observation could be used again. 
Bootstrapping can provide us with an easy way to see what might happen if we repeated an experiment a lot of times. 

To create a bootstrapped dataset, or bootstrap sample, we would select X observations from an original dataset and each time allow for an observation to be chosen even if it was already chosen previously. This means some values are likely to be repeated each time. 

![|600](https://miro.medium.com/v2/resize:fit:720/format:webp/1*lWnm3eJVe3uo95OcSg5jUA@2x.png) 
Here is an example from a [Towards Data Science Tutorial](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205). 

>[!'Bootstrapping' looks like:]
>1. Make a bootstrapped dataset
>2. Calculate something from the new dataset (e.g. the mean, standard deviation)
>3. Keep track of the calculations
>4. Repeat 1-3 lots of times
 
We can then use this to create a distribution of what might happen if we repeated an experiment multiple times - like a histogram of means generated by bootstrapping the original dataset.

To be considered <u>representative</u> and <u>independent</u> samples of the true distribution we should:
- have a big enough original dataset that sampling from it would give a good estimation of the real distribution, and 
- have a big enough bootstrap sample, relative to the main dataset, that the samples are not too strongly correlated. 

## Link to [[hypothesis testing]]

- The _Standard [[Error]]_ of the original dataset is the standard distribution of the bootstrapped dataset. 
- A 95% confidence interval is an interval that covers 95% of the bootstrapped means. 
- If this confidence interval passes 0 then we cannot reject the null hypothesis relating to our dataset. 

You can use bootstrapping for other fancier confidence intervals too. 


---
[Bootstrapping Main Ideas - StatQuest Video](https://www.youtube.com/watch?v=Xz0x-8-cgaQ)