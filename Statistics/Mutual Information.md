
Mutual information is about the shared information between two variables. 
Technically, it is the measure of dependence between two random variables. 

Unlike correlation it works for non-linear relationships which makes it a bit more useful in real life. 

It is related to [[Entropy]]. Entropy quantifies how much information there is in a random variable, so mutual information helps in reducing entropy. 

---

[Feature Selection Using Mutual Information](https://guhanesvar.medium.com/feature-selection-based-on-mutual-information-gain-for-classification-and-regression-d0f86ea5262a)